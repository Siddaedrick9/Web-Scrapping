{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvOIwFAYMXGT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# CONFIGURATION\n",
        "# ------------------------------------------------------------------------\n",
        "BASE_URL = \"https://www.........Pages/Browse.aspx\"\n",
        "DOWNLOAD_DIR = \"C:/Users/Siddhant/Desktop/Folder1\"  # Change this to your preferred path\n",
        "\n",
        "# Setup Selenium (Chrome)\n",
        "service = Service(\"D:/chromedriver-win64/chromedriver-win64/chromedriver.exe\")\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "prefs = {\"download.default_directory\": DOWNLOAD_DIR}\n",
        "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# HELPER FUNCTIONS\n",
        "# ------------------------------------------------------------------------\n",
        "def sanitize_filename(filename):\n",
        "    \"\"\"Remove or replace any characters that are invalid for file names.\"\"\"\n",
        "    return re.sub(r'[\\\\/*?:\"<>|]', '_', filename)\n",
        "\n",
        "def get_sector_cards():\n",
        "    \"\"\"Extract sector names and their URLs from the main page.\"\"\"\n",
        "    driver.get(BASE_URL)\n",
        "    wait = WebDriverWait(driver, 20)\n",
        "    try:\n",
        "        sector_cards = wait.until(EC.presence_of_all_elements_located(\n",
        "            (By.CSS_SELECTOR, \"div.col-sm-6.col-md-3.item.marginTop30 a.sectImg.lazy\")\n",
        "        ))\n",
        "    except TimeoutException:\n",
        "        print(\"Sector cards not found.\")\n",
        "        return []\n",
        "\n",
        "    sector_list = []\n",
        "    for card in sector_cards:\n",
        "        try:\n",
        "            sector_name = card.find_element(By.TAG_NAME, \"img\").get_attribute(\"alt\")\n",
        "        except Exception:\n",
        "            sector_name = card.text.strip()\n",
        "        sector_url = card.get_attribute(\"href\")\n",
        "        if sector_name and sector_url:\n",
        "            sector_list.append((sector_name, sector_url))\n",
        "    return sector_list\n",
        "\n",
        "def get_links_in_sector(sector_url):\n",
        "    \"\"\"Extract job role links from the given sector page.\"\"\"\n",
        "    job_links = []\n",
        "    driver.get(sector_url)\n",
        "    while True:\n",
        "        try:\n",
        "            wait = WebDriverWait(driver, 10)\n",
        "            job_role_elements = wait.until(EC.presence_of_all_elements_located(\n",
        "                (By.CSS_SELECTOR, \"div.padding5.bdrGray.marginLeftRight5.marginTop5 a\")\n",
        "            ))\n",
        "\n",
        "            for elem in job_role_elements:\n",
        "                job_links.append((elem.text.strip(), elem.get_attribute('href')))\n",
        "\n",
        "            next_button = driver.find_elements(By.XPATH, \"//a[span/img[contains(@class, 'ms-promlink-button-right')]]\")\n",
        "            if next_button:\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button[0])\n",
        "                next_button[0].click()\n",
        "                time.sleep(5)\n",
        "            else:\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "    return job_links\n",
        "\n",
        "# def download_pdf(title, url, sector_name):\n",
        "#     \"\"\"Download and rename PDFs for each job role.\"\"\"\n",
        "#     sector_folder = os.path.join(DOWNLOAD_DIR, sanitize_filename(sector_name))\n",
        "#     os.makedirs(sector_folder, exist_ok=True)\n",
        "\n",
        "#     driver.get(url)\n",
        "#     wait = WebDriverWait(driver, 10)\n",
        "#     try:\n",
        "#         pdf_button = wait.until(EC.presence_of_element_located(\n",
        "#             (By.XPATH, \"//input[@type='submit' and @value='Download PDF']\")))\n",
        "#         link = pdf_button.get_attribute('href')\n",
        "\n",
        "#         filename = sanitize_filename(title) + \".pdf\"\n",
        "#         filepath = os.path.join(sector_folder, filename)\n",
        "\n",
        "#         pdf_data = requests.get(link)\n",
        "#         if pdf_data.status_code == 200:\n",
        "#             with open(filepath, 'wb') as f:\n",
        "#                 f.write(pdf_data.content)\n",
        "#             print(f\"‚úÖ Downloaded PDF: {filepath}\")\n",
        "#         else:\n",
        "#             print(f\"‚ùå Failed to download {title}\")\n",
        "#     except TimeoutException:\n",
        "#         print(f\"‚ùå No PDF found for {title}\")\n",
        "\n",
        "def download_pdf(job_title, url, sector_name):\n",
        "    \"\"\"Download and rename PDFs for each job role.\"\"\"\n",
        "    sector_folder = os.path.join(DOWNLOAD_DIR, sanitize_filename(sector_name))\n",
        "    os.makedirs(sector_folder, exist_ok=True)\n",
        "\n",
        "    driver.get(url)\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "\n",
        "    try:\n",
        "        # Locate Download PDF button\n",
        "        pdf_button = wait.until(EC.presence_of_element_located(\n",
        "            (By.XPATH, \"//input[@type='submit' and contains(@value, 'Download PDF')]\")))\n",
        "\n",
        "        # Extract JavaScript onclick event\n",
        "        onclick_text = pdf_button.get_attribute(\"onclick\")\n",
        "        print(f\"üîç onclick attribute: {onclick_text}\")\n",
        "\n",
        "        # Extract PDF URL using regex\n",
        "        match = re.search(r\"window\\.open\\('([^']+)'\\)\", onclick_text)\n",
        "        if match:\n",
        "            link = match.group(1)\n",
        "            print(f\"üîó Extracted PDF URL: {link}\")\n",
        "        else:\n",
        "            print(f\"‚ùå No valid link found for {title}. Skipping.\")\n",
        "            return\n",
        "\n",
        "        # Validate URL\n",
        "        if not link.startswith(\"http\"):\n",
        "            print(f\"‚ùå Extracted URL is not valid: {link}. Skipping.\")\n",
        "            return\n",
        "\n",
        "        # Download the PDF\n",
        "        response = requests.get(link, stream=True)\n",
        "        if response.status_code == 200:\n",
        "            filename = sanitize_filename(title) + \".pdf\"\n",
        "            filepath = os.path.join(sector_folder, filename)\n",
        "\n",
        "            with open(filepath, \"wb\") as f:\n",
        "                for chunk in response.iter_content(1024):\n",
        "                    f.write(chunk)\n",
        "\n",
        "            print(f\"‚úÖ Downloaded PDF: {filepath}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Failed to download PDF for {title}, Status Code: {response.status_code}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error processing {title}: {e}\")\n",
        "\n",
        "# ------------------------------------------------------------------------\n",
        "# MAIN LOGIC\n",
        "# ------------------------------------------------------------------------\n",
        "# def main():\n",
        "#     try:\n",
        "#         sectors = get_sector_cards()\n",
        "#         print(f\"Found {len(sectors)} sectors.\")\n",
        "\n",
        "#         for name, url in sectors:\n",
        "#             print(f\"\\nProcessing sector: {name}\")\n",
        "#             job_links = get_job_links_in_sector(url)\n",
        "#             print(f\"  Found {len(job_links)} job links.\")\n",
        "\n",
        "#             for title, url in links:\n",
        "#                 download_pdf(title, url, name)\n",
        "#                 time.sleep(10)\n",
        "#     finally:\n",
        "#         driver.quit()\n",
        "\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        sectors = get_sector_cards()\n",
        "        print(f\"Found {len(sectors)} sectors.\")\n",
        "\n",
        "        # Start from the last 5 sectors in case of an interruption\n",
        "        start_index = max(0, len(sectors) - 5)\n",
        "\n",
        "        for name, url in sectors[start_index:]:\n",
        "            print(f\"\\nProcessing sector: {name}\")\n",
        "            links = get_links_in_sector(url)\n",
        "            print(f\"  Found {len(links)} links.\")\n",
        "\n",
        "            for title, url in links:\n",
        "                download_pdf(title, url, name)\n",
        "                time.sleep(10)\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "########     MAIN WORKING SELENIUM SCRAPPING SCRIPT       #########"
      ]
    }
  ]
}